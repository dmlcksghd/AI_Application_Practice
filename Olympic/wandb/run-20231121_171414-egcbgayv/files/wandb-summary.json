{"Num/train": 74, "Num/episodes": 775, "Num/timesteps": 300000, "Train/episode_reward_mean": -232.91333333333398, "Train/ratio": {"_type": "histogram", "values": [245, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.8965256810188293, 1.0522232055664062, 1.2079206705093384, 1.3636181354522705, 1.5193156003952026, 1.6750130653381348, 1.8307106494903564, 1.9864081144332886, 2.1421055793762207, 2.2978031635284424, 2.453500509262085, 2.6091980934143066, 2.764895439147949, 2.920593023300171, 3.0762903690338135, 3.231987953186035, 3.387685537338257, 3.5433828830718994, 3.699080467224121, 3.8547778129577637, 4.010475158691406, 4.166172981262207, 4.32187032699585, 4.477567672729492, 4.633265495300293, 4.7889628410339355, 4.944660186767578, 5.100358009338379, 5.2560553550720215, 5.411752700805664, 5.567450046539307, 5.723147869110107, 5.87884521484375]}, "Loss/actor_loss": -0.060583827337375294, "Loss/critic_loss": 2.0031823486249936, "Loss/entropy_loss": -0.02295982093019511, "_timestamp": 1700561217.544897, "_runtime": 6762.5378341674805, "_step": 73}