{"Num/train": 299, "Num/episodes": 4255, "Num/timesteps": 1200000, "Train/episode_reward_mean": 62.28799666666666, "Train/ratio": {"_type": "histogram", "values": [1, 2, 0, 0, 1, 1, 1, 8, 8, 2, 14, 5, 10, 177, 8, 4, 2, 2, 0, 2, 4, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2], "bins": [0.949467122554779, 0.9530924558639526, 0.9567177891731262, 0.9603431224822998, 0.9639683961868286, 0.9675937294960022, 0.9712190628051758, 0.9748443961143494, 0.978469729423523, 0.9820950627326965, 0.9857203364372253, 0.9893456697463989, 0.9929710030555725, 0.9965963363647461, 1.000221610069275, 1.0038470029830933, 1.007472276687622, 1.0110976696014404, 1.0147229433059692, 1.0183483362197876, 1.0219736099243164, 1.0255988836288452, 1.0292242765426636, 1.0328495502471924, 1.0364749431610107, 1.0401002168655396, 1.0437254905700684, 1.0473508834838867, 1.0509761571884155, 1.0546015501022339, 1.0582268238067627, 1.061852216720581, 1.0654774904251099]}, "Loss/actor_loss": -0.1442212017572495, "Loss/critic_loss": 6.150533439356794, "Loss/entropy_loss": -0.024189386516809464, "entropy_coef": 0.01, "_timestamp": 1700916392.7965028, "_runtime": 30665.431594848633, "_step": 298, "_wandb": {"runtime": 30698}}