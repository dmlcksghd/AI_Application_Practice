{"Num/train": 174, "Num/episodes": 2010, "Num/timesteps": 700000, "Train/episode_reward_mean": 43.24675999999997, "Train/ratio": {"_type": "histogram", "values": [3, 3, 8, 9, 23, 22, 33, 67, 36, 16, 8, 7, 6, 3, 0, 1, 3, 3, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1], "bins": [0.9402234554290771, 0.9477404952049255, 0.9552575349807739, 0.9627745151519775, 0.9702915549278259, 0.9778085947036743, 0.9853256344795227, 0.9928426742553711, 1.0003596544265747, 1.0078767538070679, 1.0153937339782715, 1.022910714149475, 1.0304278135299683, 1.0379447937011719, 1.045461893081665, 1.0529788732528687, 1.0604958534240723, 1.0680129528045654, 1.075529932975769, 1.0830470323562622, 1.0905640125274658, 1.098081111907959, 1.1055980920791626, 1.1131150722503662, 1.1206321716308594, 1.128149151802063, 1.1356662511825562, 1.1431832313537598, 1.1507002115249634, 1.1582173109054565, 1.1657342910766602, 1.1732513904571533, 1.180768370628357]}, "Loss/actor_loss": 0.06370176665665161, "Loss/critic_loss": 6.53378682105772, "Loss/entropy_loss": -1.7127665281295776, "entropy_coef": 0.7073222417111237, "_timestamp": 1700750975.614638, "_runtime": 17240.367437124252, "_step": 173, "_wandb": {"runtime": 17238}}