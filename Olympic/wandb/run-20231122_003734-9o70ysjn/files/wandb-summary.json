{"Num/train": 371, "Num/episodes": 3868, "Num/timesteps": 1488000, "Train/episode_reward_mean": -758.4825038760997, "Train/ratio": {"_type": "histogram", "values": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 256, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "bins": [0.5, 0.53125, 0.5625, 0.59375, 0.625, 0.65625, 0.6875, 0.71875, 0.75, 0.78125, 0.8125, 0.84375, 0.875, 0.90625, 0.9375, 0.96875, 1.0, 1.03125, 1.0625, 1.09375, 1.125, 1.15625, 1.1875, 1.21875, 1.25, 1.28125, 1.3125, 1.34375, 1.375, 1.40625, 1.4375, 1.46875, 1.5]}, "Loss/actor_loss": 0.42148522687455015, "Loss/critic_loss": 15.818766583396544, "Loss/entropy_loss": -0.9649572372436523, "entropy_coef": 0.3979414735656033, "_timestamp": 1700612230.755458, "_runtime": 31176.020714998245, "_step": 370, "_wandb": {"runtime": 31257}}