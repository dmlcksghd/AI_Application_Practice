{"Num/train": 766, "Num/episodes": 11068, "Num/timesteps": 3068000, "Train/episode_reward_mean": 68.04814999999998, "Train/ratio": {"_type": "histogram", "values": [1, 0, 2, 4, 2, 12, 2, 2, 5, 5, 192, 7, 3, 3, 3, 0, 2, 0, 1, 3, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.9539218544960022, 0.9582945108413696, 0.9626672267913818, 0.9670398831367493, 0.9714125990867615, 0.9757852554321289, 0.9801579117774963, 0.9845306277275085, 0.988903284072876, 0.9932760000228882, 0.9976486563682556, 1.002021312713623, 1.0063940286636353, 1.0107667446136475, 1.0151393413543701, 1.0195120573043823, 1.0238847732543945, 1.0282573699951172, 1.0326300859451294, 1.0370028018951416, 1.0413755178451538, 1.0457481145858765, 1.0501208305358887, 1.0544935464859009, 1.0588661432266235, 1.0632388591766357, 1.067611575126648, 1.0719841718673706, 1.0763568878173828, 1.080729603767395, 1.0851023197174072, 1.0894749164581299, 1.093847632408142]}, "Loss/actor_loss": 0.10152025686526892, "Loss/critic_loss": 3.670714441473766, "Loss/entropy_loss": -0.024189386516809464, "entropy_coef": 0.01, "_timestamp": 1701005306.5239797, "_runtime": 75992.57886576653, "_step": 765, "_wandb": {"runtime": 76011}}