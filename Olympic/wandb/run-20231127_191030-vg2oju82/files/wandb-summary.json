{"Num/train": 93, "Num/episodes": 1373, "Num/timesteps": 376000, "Train/episode_reward_mean": 56.04777666666665, "Train/ratio": {"_type": "histogram", "values": [1, 2, 8, 14, 11, 185, 16, 4, 5, 5, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.9542579650878906, 0.9623749852180481, 0.9704920649528503, 0.9786090850830078, 0.9867261648178101, 0.9948431849479675, 1.002960205078125, 1.0110772848129272, 1.0191943645477295, 1.0273113250732422, 1.0354284048080444, 1.0435454845428467, 1.051662564277649, 1.0597795248031616, 1.0678966045379639, 1.0760136842727661, 1.0841307640075684, 1.092247724533081, 1.1003648042678833, 1.1084818840026855, 1.1165988445281982, 1.1247159242630005, 1.1328330039978027, 1.140950083732605, 1.1490670442581177, 1.15718412399292, 1.1653012037277222, 1.1734181642532349, 1.181535243988037, 1.1896523237228394, 1.1977694034576416, 1.2058863639831543, 1.2140034437179565]}, "Loss/actor_loss": 0.3516107592479356, "Loss/critic_loss": 5.6222828162677825, "Loss/entropy_loss": -0.012094693258404732, "entropy_coef": 0.005, "_timestamp": 1701088643.4654512, "_runtime": 8812.760290145874, "_step": 92, "_wandb": {"runtime": 8868}}