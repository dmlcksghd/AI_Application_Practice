{"Num/train": 10, "Num/episodes": 113, "Num/timesteps": 44000, "Train/episode_reward_mean": -785.9810762463487, "Train/ratio": {"_type": "histogram", "values": [5, 45, 53, 22, 58, 33, 20, 11, 3, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], "bins": [0.7490801811218262, 0.7862866520881653, 0.8234931230545044, 0.8606995940208435, 0.8979060649871826, 0.9351125359535217, 0.9723190069198608, 1.0095254182815552, 1.046731948852539, 1.0839383602142334, 1.1211448907852173, 1.1583513021469116, 1.1955578327178955, 1.2327642440795898, 1.2699707746505737, 1.307177186012268, 1.344383716583252, 1.3815901279449463, 1.4187965393066406, 1.4560030698776245, 1.4932094812393188, 1.5304160118103027, 1.567622423171997, 1.604828953742981, 1.6420353651046753, 1.6792418956756592, 1.7164483070373535, 1.7536548376083374, 1.7908612489700317, 1.8280677795410156, 1.86527419090271, 1.9024807214736938, 1.9396871328353882]}, "Loss/actor_loss": -0.024043096820273065, "Loss/critic_loss": 22.29222389492937, "Loss/entropy_loss": -2.3947459422644752, "entropy_coef": 0.99, "_timestamp": 1700565833.1826327, "_runtime": 1154.0747985839844, "_step": 9, "_wandb": {"runtime": 1248}}