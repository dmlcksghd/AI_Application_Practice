{"Num/train": 295, "Num/episodes": 3491, "Num/timesteps": 1184000, "Train/episode_reward_mean": -56.60429666666661, "Train/ratio": {"_type": "histogram", "values": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 256, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "bins": [0.5, 0.53125, 0.5625, 0.59375, 0.625, 0.65625, 0.6875, 0.71875, 0.75, 0.78125, 0.8125, 0.84375, 0.875, 0.90625, 0.9375, 0.96875, 1.0, 1.03125, 1.0625, 1.09375, 1.125, 1.15625, 1.1875, 1.21875, 1.25, 1.28125, 1.3125, 1.34375, 1.375, 1.40625, 1.4375, 1.46875, 1.5]}, "Loss/actor_loss": 0.10938328160473736, "Loss/critic_loss": 0.4023438569318543, "Loss/entropy_loss": -1.15495765209198, "entropy_coef": 0.47630222140065615, "_timestamp": 1701545307.192613, "_runtime": 35094.81915187836, "_step": 294, "_wandb": {"runtime": 35107}}