{"Num/train": 1, "Num/episodes": 28, "Num/timesteps": 8000, "Train/episode_reward_mean": 27.271374999999985, "Train/ratio": {"_type": "histogram", "values": [2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 251, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.22985295951366425, 0.2740016281604767, 0.3181503117084503, 0.36229899525642395, 0.4064476788043976, 0.4505963623523712, 0.49474501609802246, 0.5388936996459961, 0.5830423831939697, 0.6271910667419434, 0.671339750289917, 0.7154884338378906, 0.7596371173858643, 0.8037858009338379, 0.8479344844818115, 0.8920831084251404, 0.936231791973114, 0.9803804755210876, 1.024529218673706, 1.0686779022216797, 1.1128265857696533, 1.1569751501083374, 1.201123833656311, 1.2452725172042847, 1.2894212007522583, 1.333569884300232, 1.3777185678482056, 1.4218672513961792, 1.4660159349441528, 1.5101646184921265, 1.5543133020401, 1.5984619855880737, 1.6426106691360474]}, "Loss/actor_loss": 0.41543599397404696, "Loss/critic_loss": 4.464572115380277, "Loss/entropy_loss": -0.012093101228957855, "entropy_coef": 0.005, "_timestamp": 1701487104.5159414, "_runtime": 146.32260727882385, "_step": 0, "_wandb": {"runtime": 193}}