{"Num/train": 379, "Num/episodes": 4772, "Num/timesteps": 1520000, "Train/episode_reward_mean": 28.638656666666655, "Train/ratio": {"_type": "histogram", "values": [1, 2, 1, 1, 6, 12, 16, 11, 182, 8, 3, 3, 2, 4, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.9427156448364258, 0.9492838382720947, 0.9558520317077637, 0.9624202847480774, 0.9689884781837463, 0.9755566716194153, 0.9821248650550842, 0.9886930584907532, 0.9952613115310669, 1.0018295049667358, 1.0083976984024048, 1.0149658918380737, 1.0215340852737427, 1.0281022787094116, 1.0346704721450806, 1.0412386655807495, 1.047806978225708, 1.054375171661377, 1.060943365097046, 1.0675115585327148, 1.0740797519683838, 1.0806479454040527, 1.0872161388397217, 1.0937843322753906, 1.1003525257110596, 1.1069207191467285, 1.1134889125823975, 1.120057225227356, 1.126625418663025, 1.1331936120986938, 1.1397618055343628, 1.1463299989700317, 1.1528981924057007]}, "Loss/actor_loss": -0.535048312355554, "Loss/critic_loss": 0.7544277669713702, "Loss/entropy_loss": -1.451415777206421, "entropy_coef": 0.5993283347846304, "_timestamp": 1701615004.1836324, "_runtime": 36684.75936126709, "_step": 378, "_wandb": {"runtime": 36683}}