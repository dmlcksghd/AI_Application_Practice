{"Num/train": 594, "Num/episodes": 8455, "Num/timesteps": 2380000, "Train/episode_reward_mean": 54.922969999999985, "Train/ratio": {"_type": "histogram", "values": [1, 4, 0, 2, 5, 13, 9, 12, 8, 170, 8, 6, 1, 3, 1, 1, 0, 2, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1], "bins": [0.9475314021110535, 0.952985405921936, 0.9584394693374634, 0.963893473148346, 0.9693474769592285, 0.9748015403747559, 0.9802555441856384, 0.985709547996521, 0.9911636114120483, 0.9966176152229309, 1.0020716190338135, 1.0075256824493408, 1.0129797458648682, 1.018433690071106, 1.0238877534866333, 1.0293418169021606, 1.0347957611083984, 1.0402498245239258, 1.0457038879394531, 1.051157832145691, 1.0566118955612183, 1.0620659589767456, 1.0675199031829834, 1.0729739665985107, 1.078428030014038, 1.0838819742202759, 1.0893360376358032, 1.0947901010513306, 1.1002440452575684, 1.1056981086730957, 1.111152172088623, 1.1166061162948608, 1.1220601797103882]}, "Loss/actor_loss": 0.47548131487142015, "Loss/critic_loss": 2.3697150022336233, "Loss/entropy_loss": -0.012094693258404732, "entropy_coef": 0.005, "_timestamp": 1701067468.6316073, "_runtime": 58912.307178258896, "_step": 593, "_wandb": {"runtime": 58911}}