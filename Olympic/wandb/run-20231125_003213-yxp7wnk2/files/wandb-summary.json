{"Num/train": 9, "Num/episodes": 128, "Num/timesteps": 40000, "Train/episode_reward_mean": 31.514559999999964, "Train/ratio": {"_type": "histogram", "values": [1, 0, 0, 0, 0, 8, 6, 10, 29, 182, 9, 4, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.780481219291687, 0.8048611283302307, 0.8292410373687744, 0.8536209464073181, 0.8780008554458618, 0.9023807644844055, 0.9267606735229492, 0.9511405825614929, 0.9755204916000366, 0.9999004602432251, 1.024280309677124, 1.0486602783203125, 1.0730401277542114, 1.0974200963974, 1.1217999458312988, 1.1461799144744873, 1.1705598831176758, 1.1949397325515747, 1.2193197011947632, 1.243699550628662, 1.2680795192718506, 1.2924593687057495, 1.316839337348938, 1.341219186782837, 1.3655991554260254, 1.3899790048599243, 1.4143589735031128, 1.4387388229370117, 1.4631187915802002, 1.4874986410140991, 1.5118786096572876, 1.5362584590911865, 1.560638427734375]}, "Loss/actor_loss": -0.39002294117627384, "Loss/critic_loss": 3.253713051011806, "Loss/entropy_loss": -0.024189386516809464, "entropy_coef": 0.01, "_timestamp": 1700840880.2431927, "_runtime": 946.2723686695099, "_step": 8, "_wandb": {"runtime": 944}}