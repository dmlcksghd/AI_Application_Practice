{"Num/train": 867, "Num/episodes": 10930, "Num/timesteps": 3472000, "Train/episode_reward_mean": 45.31473999999998, "Train/ratio": {"_type": "histogram", "values": [2, 2, 1, 3, 6, 18, 18, 19, 11, 108, 13, 11, 11, 5, 1, 4, 2, 1, 4, 3, 1, 2, 0, 0, 1, 2, 0, 2, 3, 1, 0, 1], "bins": [0.9487998485565186, 0.953987717628479, 0.9591756463050842, 0.9643635153770447, 0.9695514440536499, 0.9747393131256104, 0.9799272418022156, 0.985115110874176, 0.9903030395507812, 0.9954909086227417, 1.0006787776947021, 1.0058666467666626, 1.0110546350479126, 1.016242504119873, 1.0214303731918335, 1.026618242263794, 1.031806230545044, 1.0369940996170044, 1.0421819686889648, 1.0473698377609253, 1.0525577068328857, 1.0577456951141357, 1.0629335641860962, 1.0681214332580566, 1.073309302330017, 1.0784971714019775, 1.0836851596832275, 1.088873028755188, 1.0940608978271484, 1.0992487668991089, 1.1044367551803589, 1.1096246242523193, 1.1148124933242798]}, "Loss/actor_loss": 0.1280739956634039, "Loss/critic_loss": 2.0819768258608797, "Loss/entropy_loss": -0.8016096353530884, "entropy_coef": 0.3311032747574917, "_timestamp": 1700839378.0339835, "_runtime": 87661.69534349442, "_step": 866, "_wandb": {"runtime": 87687}}