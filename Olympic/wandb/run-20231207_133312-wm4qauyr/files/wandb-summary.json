{"Num/train": 177, "Num/episodes": 2191, "Num/timesteps": 712000, "Train/episode_reward_mean": -37.20026333333335, "Train/ratio": {"_type": "histogram", "values": [1, 1, 1, 3, 7, 4, 10, 11, 11, 4, 179, 4, 3, 2, 2, 2, 1, 2, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1], "bins": [0.9362229108810425, 0.9424624443054199, 0.9487019777297974, 0.9549415111541748, 0.9611810445785522, 0.9674205780029297, 0.9736601114273071, 0.9798996448516846, 0.986139178276062, 0.9923786520957947, 0.9986181855201721, 1.0048577785491943, 1.0110973119735718, 1.0173368453979492, 1.0235763788223267, 1.029815912246704, 1.036055326461792, 1.0422948598861694, 1.0485343933105469, 1.0547739267349243, 1.0610134601593018, 1.0672529935836792, 1.0734925270080566, 1.079732060432434, 1.0859715938568115, 1.092211127281189, 1.0984506607055664, 1.1046901941299438, 1.1109297275543213, 1.1171692609786987, 1.1234087944030762, 1.1296483278274536, 1.135887861251831]}, "Loss/actor_loss": 0.05983035328665308, "Loss/critic_loss": 0.3263136246992696, "Loss/entropy_loss": -0.012094693258404732, "entropy_coef": 0.005, "_timestamp": 1701942015.1163485, "_runtime": 18422.602816581726, "_step": 176, "_wandb": {"runtime": 18542}}