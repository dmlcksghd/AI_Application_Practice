{"Num/train": 999, "Num/episodes": 12137, "Num/timesteps": 4000000, "Train/episode_reward_mean": -4.527076666666672, "Train/ratio": {"_type": "histogram", "values": [2, 1, 2, 4, 5, 9, 4, 13, 8, 6, 170, 1, 3, 5, 4, 2, 2, 2, 3, 0, 2, 0, 0, 3, 0, 0, 1, 0, 1, 1, 1, 1], "bins": [0.9471390843391418, 0.9520373344421387, 0.9569355845451355, 0.9618338346481323, 0.9667320847511292, 0.971630334854126, 0.9765285849571228, 0.9814268350601196, 0.9863250851631165, 0.9912233352661133, 0.9961215853691101, 1.001019835472107, 1.005918025970459, 1.0108163356781006, 1.0157145261764526, 1.0206128358840942, 1.0255110263824463, 1.030409336090088, 1.03530752658844, 1.0402058362960815, 1.0451040267944336, 1.0500023365020752, 1.0549005270004272, 1.0597988367080688, 1.064697027206421, 1.0695953369140625, 1.0744935274124146, 1.0793918371200562, 1.0842900276184082, 1.0891883373260498, 1.0940865278244019, 1.0989848375320435, 1.1038830280303955]}, "Loss/actor_loss": -0.20032759011713086, "Loss/critic_loss": 0.8810022474585041, "Loss/entropy_loss": -0.690386950969696, "entropy_coef": 0.2851968533133673, "_timestamp": 1701782189.768602, "_runtime": 98335.82524394989, "_step": 998, "_wandb": {"runtime": 98367}}