{"Num/train": 4, "Num/episodes": 63, "Num/timesteps": 20000, "Train/episode_reward_mean": 25.850616666666642, "Train/ratio": {"_type": "histogram", "values": [1, 1, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 2, 0, 1, 238, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.8009900450706482, 0.8140957355499268, 0.8272013664245605, 0.8403070569038391, 0.8534127473831177, 0.8665183782577515, 0.87962406873703, 0.8927297592163086, 0.9058353900909424, 0.918941080570221, 0.9320467710494995, 0.9451524019241333, 0.9582580924034119, 0.9713637828826904, 0.9844694137573242, 0.9975751042366028, 1.0106807947158813, 1.0237864255905151, 1.036892056465149, 1.0499978065490723, 1.063103437423706, 1.0762090682983398, 1.0893148183822632, 1.102420449256897, 1.1155260801315308, 1.128631830215454, 1.141737461090088, 1.1548430919647217, 1.167948842048645, 1.1810544729232788, 1.1941601037979126, 1.207265853881836, 1.2203714847564697]}, "Loss/actor_loss": -0.11529354180494744, "Loss/critic_loss": 1.78631003306758, "Loss/entropy_loss": -0.012094693258404732, "entropy_coef": 0.005, "_timestamp": 1701920623.662645, "_runtime": 475.7036681175232, "_step": 3, "_wandb": {"runtime": 474}}