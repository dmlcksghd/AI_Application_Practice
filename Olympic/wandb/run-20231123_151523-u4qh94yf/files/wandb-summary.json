{"Num/train": 80, "Num/episodes": 851, "Num/timesteps": 324000, "Train/episode_reward_mean": -10.046576666666699, "Train/ratio": {"_type": "histogram", "values": [1, 0, 1, 4, 4, 7, 20, 21, 24, 36, 69, 24, 13, 5, 8, 2, 4, 4, 4, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.9363693594932556, 0.9426567554473877, 0.9489441514015198, 0.9552315473556519, 0.9615188837051392, 0.9678062796592712, 0.9740936756134033, 0.9803810715675354, 0.9866684675216675, 0.9929558634757996, 0.9992431998252869, 1.005530595779419, 1.0118180513381958, 1.018105387687683, 1.0243927240371704, 1.0306801795959473, 1.0369675159454346, 1.0432549715042114, 1.0495423078536987, 1.0558297634124756, 1.062117099761963, 1.0684044361114502, 1.074691891670227, 1.0809792280197144, 1.0872666835784912, 1.0935540199279785, 1.0998413562774658, 1.1061288118362427, 1.11241614818573, 1.1187036037445068, 1.1249909400939941, 1.131278395652771, 1.1375657320022583]}, "Loss/actor_loss": -0.06214497124368165, "Loss/critic_loss": 0.12892588480846376, "Loss/entropy_loss": -2.171196699142456, "entropy_coef": 0.8964835494507453, "_timestamp": 1700727565.0897691, "_runtime": 7441.408870220184, "_step": 79, "_wandb": {"runtime": 7440}}