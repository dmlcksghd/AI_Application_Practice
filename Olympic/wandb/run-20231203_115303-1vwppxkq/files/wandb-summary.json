{"Num/train": 36, "Num/episodes": 464, "Num/timesteps": 148000, "Train/episode_reward_mean": 37.82542, "Train/ratio": {"_type": "histogram", "values": [3, 1, 5, 13, 15, 9, 187, 4, 1, 7, 2, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.9576300382614136, 0.9640469551086426, 0.9704638719558716, 0.9768807888031006, 0.9832977056503296, 0.9897146224975586, 0.9961315393447876, 1.0025484561920166, 1.0089653730392456, 1.0153822898864746, 1.0217992067337036, 1.0282161235809326, 1.0346330404281616, 1.0410499572753906, 1.0474668741226196, 1.0538837909698486, 1.0603008270263672, 1.0667177438735962, 1.0731346607208252, 1.0795515775680542, 1.0859684944152832, 1.0923854112625122, 1.0988023281097412, 1.1052192449569702, 1.1116361618041992, 1.1180530786514282, 1.1244699954986572, 1.1308869123458862, 1.1373038291931152, 1.1437207460403442, 1.1501376628875732, 1.1565545797348022, 1.1629714965820312]}, "Loss/actor_loss": 0.008057459320382326, "Loss/critic_loss": 5.550932968290904, "Loss/entropy_loss": -2.2688002586364746, "entropy_coef": 0.936789704044803, "_timestamp": 1701575452.5514245, "_runtime": 3469.4457654953003, "_step": 35, "_wandb": {"runtime": 3467}}