{"Num/train": 355, "Num/episodes": 4396, "Num/timesteps": 1424000, "Train/episode_reward_mean": -1.6582133333333724, "Train/ratio": {"_type": "histogram", "values": [1, 0, 0, 1, 2, 1, 1, 4, 7, 9, 3, 202, 4, 8, 3, 4, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1], "bins": [0.934526264667511, 0.9402329921722412, 0.9459397196769714, 0.9516463875770569, 0.9573531150817871, 0.9630598425865173, 0.9687665700912476, 0.974473237991333, 0.9801799654960632, 0.9858866930007935, 0.9915934205055237, 0.9973001480102539, 1.0030068159103394, 1.0087136030197144, 1.0144202709197998, 1.0201269388198853, 1.0258337259292603, 1.0315403938293457, 1.0372471809387207, 1.0429538488388062, 1.0486605167388916, 1.0543673038482666, 1.060073971748352, 1.0657806396484375, 1.0714874267578125, 1.077194094657898, 1.082900881767273, 1.0886075496673584, 1.0943142175674438, 1.1000210046768188, 1.1057276725769043, 1.1114344596862793, 1.1171411275863647]}, "Loss/actor_loss": 0.11982794892999234, "Loss/critic_loss": 0.9819750999555151, "Loss/entropy_loss": -0.012094693258404732, "entropy_coef": 0.005, "_timestamp": 1701920129.2382789, "_runtime": 33940.07121992111, "_step": 354, "_wandb": {"runtime": 33939}}