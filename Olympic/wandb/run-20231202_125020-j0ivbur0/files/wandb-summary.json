{"Num/train": 2, "Num/episodes": 42, "Num/timesteps": 12000, "Train/episode_reward_mean": 40.50334333333333, "Train/ratio": {"_type": "histogram", "values": [2, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 242, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1], "bins": [0.6315969824790955, 0.6595930457115173, 0.6875890493392944, 0.7155851125717163, 0.7435811758041382, 0.7715771794319153, 0.7995732426643372, 0.827569305896759, 0.8555653095245361, 0.883561372756958, 0.9115574359893799, 0.939553439617157, 0.9675495028495789, 0.9955455660820007, 1.0235415697097778, 1.0515376329421997, 1.0795336961746216, 1.1075297594070435, 1.1355257034301758, 1.1635217666625977, 1.1915178298950195, 1.2195138931274414, 1.2475099563598633, 1.2755060195922852, 1.3035019636154175, 1.3314980268478394, 1.3594940900802612, 1.387490153312683, 1.415486216545105, 1.4434822797775269, 1.4714782238006592, 1.499474287033081, 1.527470350265503]}, "Loss/actor_loss": -0.4375331506937222, "Loss/critic_loss": 5.717094169598754, "Loss/entropy_loss": -2.381250250416417, "entropy_coef": 0.9827133233013189, "_timestamp": 1701489316.1325042, "_runtime": 295.9260561466217, "_step": 1, "_wandb": {"runtime": 294}}