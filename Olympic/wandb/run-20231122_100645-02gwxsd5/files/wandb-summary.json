{"Num/train": 99, "Num/episodes": 1024, "Num/timesteps": 400000, "Train/episode_reward_mean": -250.71000000000063, "Train/ratio": {"_type": "histogram", "values": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 256, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "bins": [0.5, 0.53125, 0.5625, 0.59375, 0.625, 0.65625, 0.6875, 0.71875, 0.75, 0.78125, 0.8125, 0.84375, 0.875, 0.90625, 0.9375, 0.96875, 1.0, 1.03125, 1.0625, 1.09375, 1.125, 1.15625, 1.1875, 1.21875, 1.25, 1.28125, 1.3125, 1.34375, 1.375, 1.40625, 1.4375, 1.46875, 1.5]}, "Loss/actor_loss": -0.10612321240567071, "Loss/critic_loss": 1.9847698892508783, "Loss/entropy_loss": -0.7121465802192688, "entropy_coef": 0.29082012332029616, "_timestamp": 1700624104.8340216, "_runtime": 8899.45449757576, "_step": 98, "_wandb": {"runtime": 8931}}