{"Num/train": 5, "Num/episodes": 77, "Num/timesteps": 24000, "Train/episode_reward_mean": 25.722420000000014, "Train/ratio": {"_type": "histogram", "values": [2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 0, 0, 1, 2, 238, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], "bins": [0.8490999937057495, 0.8597827553749084, 0.8704655170440674, 0.8811482787132263, 0.8918310403823853, 0.9025138020515442, 0.9131965637207031, 0.9238793253898621, 0.934562087059021, 0.9452449083328247, 0.9559276700019836, 0.9666104316711426, 0.9772931933403015, 0.9879759550094604, 0.9986587166786194, 1.0093414783477783, 1.020024299621582, 1.0307070016860962, 1.0413898229599, 1.052072525024414, 1.0627553462982178, 1.073438048362732, 1.0841208696365356, 1.0948035717010498, 1.1054863929748535, 1.1161690950393677, 1.1268519163131714, 1.1375346183776855, 1.1482174396514893, 1.1589001417160034, 1.1695829629898071, 1.1802656650543213, 1.190948486328125]}, "Loss/actor_loss": -0.38149719302782853, "Loss/critic_loss": 5.516959276404433, "Loss/entropy_loss": -2.3654446601867676, "entropy_coef": 0.9754802785797199, "_timestamp": 1701488883.9199653, "_runtime": 635.9833333492279, "_step": 4, "_wandb": {"runtime": 745}}