{"Num/train": 7, "Num/episodes": 108, "Num/timesteps": 32000, "Train/episode_reward_mean": 38.159769999999995, "Train/ratio": {"_type": "histogram", "values": [1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 3, 1, 0, 2, 2, 2, 1, 2, 2, 228, 0, 3, 0, 0, 0, 0, 3, 0, 0, 1, 1], "bins": [0.8468546867370605, 0.8545001745223999, 0.8621456623077393, 0.8697911500930786, 0.877436637878418, 0.8850821256637573, 0.8927276134490967, 0.900373101234436, 0.9080185890197754, 0.9156640768051147, 0.9233095645904541, 0.9309550523757935, 0.9386005401611328, 0.9462460279464722, 0.9538915157318115, 0.9615370035171509, 0.9691824913024902, 0.9768279790878296, 0.984473466873169, 0.9921189546585083, 0.9997644424438477, 1.007409930229187, 1.0150554180145264, 1.0227009057998657, 1.030346393585205, 1.0379918813705444, 1.0456373691558838, 1.0532828569412231, 1.0609283447265625, 1.0685738325119019, 1.0762193202972412, 1.0838648080825806, 1.09151029586792]}, "Loss/actor_loss": -0.27330116259945575, "Loss/critic_loss": 3.752475054853706, "Loss/entropy_loss": -2.350421905517578, "entropy_coef": 0.9704914296062561, "_timestamp": 1701546223.0891085, "_runtime": 842.2446994781494, "_step": 6, "_wandb": {"runtime": 909}}