{"Num/train": 34, "Num/episodes": 377, "Num/timesteps": 140000, "Train/episode_reward_mean": 17.43056999999998, "Train/ratio": {"_type": "histogram", "values": [1, 0, 5, 0, 8, 5, 9, 21, 21, 24, 23, 56, 21, 15, 6, 10, 7, 6, 4, 4, 0, 3, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1], "bins": [0.942105233669281, 0.9470232725143433, 0.9519413113594055, 0.9568593502044678, 0.96177738904953, 0.9666954278945923, 0.9716134667396545, 0.9765315055847168, 0.981449544429779, 0.9863675832748413, 0.9912856221199036, 0.9962036609649658, 1.0011216402053833, 1.0060397386550903, 1.0109577178955078, 1.0158758163452148, 1.0207937955856323, 1.0257118940353394, 1.0306298732757568, 1.0355479717254639, 1.0404659509658813, 1.0453840494155884, 1.0503020286560059, 1.055220127105713, 1.0601381063461304, 1.0650562047958374, 1.0699741840362549, 1.074892282485962, 1.0798102617263794, 1.0847283601760864, 1.089646339416504, 1.094564437866211, 1.0994824171066284]}, "Loss/actor_loss": -0.31217160612269634, "Loss/critic_loss": 5.276359275877476, "Loss/entropy_loss": -2.0738255977630615, "entropy_coef": 0.8563862172184364, "_timestamp": 1700733629.6068232, "_runtime": 3217.2670052051544, "_step": 33, "_wandb": {"runtime": 3215}}