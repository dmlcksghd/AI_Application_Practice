{"Num/train": 90, "Num/episodes": 1323, "Num/timesteps": 364000, "Train/episode_reward_mean": 74.95756999999999, "Train/ratio": {"_type": "histogram", "values": [1, 0, 2, 1, 2, 3, 5, 6, 13, 12, 10, 9, 25, 128, 8, 2, 6, 5, 4, 2, 3, 2, 1, 2, 1, 0, 2, 0, 0, 0, 0, 1], "bins": [0.9443716406822205, 0.948647677898407, 0.9529236555099487, 0.9571996927261353, 0.961475670337677, 0.9657517075538635, 0.97002774477005, 0.9743037223815918, 0.9785797595977783, 0.9828557372093201, 0.9871317744255066, 0.9914078116416931, 0.9956837892532349, 0.9999598264694214, 1.004235863685608, 1.0085117816925049, 1.0127878189086914, 1.017063856124878, 1.0213398933410645, 1.025615930557251, 1.029891848564148, 1.0341678857803345, 1.038443922996521, 1.0427199602127075, 1.046995997428894, 1.051271915435791, 1.0555479526519775, 1.059823989868164, 1.0641000270843506, 1.068376064300537, 1.072651982307434, 1.0769280195236206, 1.0812040567398071]}, "Loss/actor_loss": -0.17009133980206403, "Loss/critic_loss": 2.9502163166352497, "Loss/entropy_loss": -0.024152935555264834, "entropy_coef": 0.01, "_timestamp": 1700927251.067881, "_runtime": 9340.54091501236, "_step": 89, "_wandb": {"runtime": 9339}}