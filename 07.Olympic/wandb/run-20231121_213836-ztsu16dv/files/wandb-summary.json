{"Num/train": 49, "Num/episodes": 523, "Num/timesteps": 200000, "Train/episode_reward_mean": -797.527938607456, "Train/ratio": {"_type": "histogram", "values": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 256, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "bins": [0.5, 0.53125, 0.5625, 0.59375, 0.625, 0.65625, 0.6875, 0.71875, 0.75, 0.78125, 0.8125, 0.84375, 0.875, 0.90625, 0.9375, 0.96875, 1.0, 1.03125, 1.0625, 1.09375, 1.125, 1.15625, 1.1875, 1.21875, 1.25, 1.28125, 1.3125, 1.34375, 1.375, 1.40625, 1.4375, 1.46875, 1.5]}, "Loss/actor_loss": 0.27189317610875896, "Loss/critic_loss": 16.21045465607797, "Loss/entropy_loss": -0.26124536991119385, "entropy_coef": 0.010000000000000148, "_timestamp": 1700574857.1617768, "_runtime": 4540.554725885391, "_step": 48, "_wandb": {"runtime": 4572}}