{"Num/train": 47, "Num/episodes": 646, "Num/timesteps": 192000, "Train/episode_reward_mean": 69.3993233333333, "Train/ratio": {"_type": "histogram", "values": [1, 0, 0, 2, 3, 10, 7, 16, 25, 18, 136, 7, 11, 5, 3, 2, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1], "bins": [0.9511079788208008, 0.9557083249092102, 0.9603087306022644, 0.9649090766906738, 0.969509482383728, 0.9741098284721375, 0.9787101745605469, 0.9833105802536011, 0.9879109263420105, 0.9925112724304199, 0.9971116781234741, 1.0017120838165283, 1.006312370300293, 1.0109127759933472, 1.0155131816864014, 1.020113468170166, 1.0247138738632202, 1.0293142795562744, 1.033914566040039, 1.0385149717330933, 1.0431153774261475, 1.047715663909912, 1.0523160696029663, 1.0569164752960205, 1.0615167617797852, 1.0661171674728394, 1.0707175731658936, 1.0753179788589478, 1.0799182653427124, 1.0845186710357666, 1.0891190767288208, 1.0937193632125854, 1.0983197689056396]}, "Loss/actor_loss": -0.3589662251324063, "Loss/critic_loss": 6.2093246921416245, "Loss/entropy_loss": -0.11813781403966489, "entropy_coef": 0.04881428548789553, "_timestamp": 1700884597.9388514, "_runtime": 5471.7175352573395, "_step": 46, "_wandb": {"runtime": 5470}}