{"Num/train": 3, "Num/episodes": 41, "Num/timesteps": 16000, "Train/episode_reward_mean": -784.7401073580659, "Train/ratio": {"_type": "histogram", "values": [107, 114, 27, 6, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.37927910685539246, 0.6868610978126526, 0.9944430589675903, 1.3020249605178833, 1.6096069812774658, 1.9171888828277588, 2.2247707843780518, 2.532352924346924, 2.839934825897217, 3.1475167274475098, 3.4550986289978027, 3.762680768966675, 4.070262432098389, 4.37784481048584, 4.685426712036133, 4.993008613586426, 5.300590515136719, 5.608172416687012, 5.915754318237305, 6.223336219787598, 6.530918121337891, 6.838500499725342, 7.146082401275635, 7.453664302825928, 7.761246204376221, 8.068828582763672, 8.376410484313965, 8.683992385864258, 8.99157428741455, 9.299156188964844, 9.606738090515137, 9.91431999206543, 10.221901893615723]}, "Loss/actor_loss": 4.633746961021936, "Loss/critic_loss": 18.196381466568155, "Loss/entropy_loss": -1.304582674221326, "entropy_coef": 0.8975824147163817, "_timestamp": 1700580338.3034902, "_runtime": 334.2566921710968, "_step": 2, "_wandb": {"runtime": 340}}