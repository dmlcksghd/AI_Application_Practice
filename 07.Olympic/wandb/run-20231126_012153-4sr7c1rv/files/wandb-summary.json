{"Num/train": 692, "Num/episodes": 10019, "Num/timesteps": 2772000, "Train/episode_reward_mean": 45.621379999999995, "Train/ratio": {"_type": "histogram", "values": [2, 0, 1, 0, 0, 0, 8, 5, 4, 4, 5, 4, 3, 198, 4, 6, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1], "bins": [0.9495935440063477, 0.9532121419906616, 0.9568307399749756, 0.9604493975639343, 0.9640679955482483, 0.9676865935325623, 0.971305251121521, 0.974923849105835, 0.9785424470901489, 0.9821610450744629, 0.9857796430587769, 0.9893983006477356, 0.9930168986320496, 0.9966354966163635, 1.0002541542053223, 1.0038727521896362, 1.0074913501739502, 1.0111099481582642, 1.0147285461425781, 1.018347144126892, 1.021965742111206, 1.0255844593048096, 1.0292030572891235, 1.0328216552734375, 1.0364402532577515, 1.0400588512420654, 1.0436774492263794, 1.0472960472106934, 1.0509147644042969, 1.0545333623886108, 1.0581519603729248, 1.0617705583572388, 1.0653891563415527]}, "Loss/actor_loss": 0.049525880590581925, "Loss/critic_loss": 3.331769698159669, "Loss/entropy_loss": -0.024189386516809464, "entropy_coef": 0.01, "_timestamp": 1700997601.0170696, "_runtime": 68287.07195568085, "_step": 691}