{"Num/train": 99, "Num/episodes": 1344, "Num/timesteps": 400000, "Train/episode_reward_mean": 42.63951333333331, "Train/ratio": {"_type": "histogram", "values": [1, 0, 0, 0, 1, 1, 1, 0, 3, 3, 3, 7, 17, 16, 11, 16, 21, 107, 9, 7, 4, 1, 4, 5, 5, 4, 2, 0, 1, 1, 1, 4], "bins": [0.91379714012146, 0.9187451601028442, 0.9236931204795837, 0.928641140460968, 0.9335891604423523, 0.9385371208190918, 0.9434851408004761, 0.9484331607818604, 0.9533811807632446, 0.9583291411399841, 0.9632771611213684, 0.9682251811027527, 0.9731731414794922, 0.9781211614608765, 0.9830691814422607, 0.9880171418190002, 0.9929651618003845, 0.9979131817817688, 1.0028611421585083, 1.0078091621398926, 1.0127571821212769, 1.0177052021026611, 1.0226532220840454, 1.0276011228561401, 1.0325491428375244, 1.0374971628189087, 1.042445182800293, 1.0473932027816772, 1.0523412227630615, 1.0572891235351562, 1.0622371435165405, 1.0671851634979248, 1.072133183479309]}, "Loss/actor_loss": 0.5217739675218059, "Loss/critic_loss": 6.624185571144986, "Loss/entropy_loss": -0.3824206590652466, "entropy_coef": 0.15771937819621587, "_timestamp": 1700850931.7642949, "_runtime": 9743.299898862839, "_step": 98, "_wandb": {"runtime": 9776}}