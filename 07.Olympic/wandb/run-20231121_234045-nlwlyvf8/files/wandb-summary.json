{"Num/train": 19, "Num/episodes": 207, "Num/timesteps": 80000, "Train/episode_reward_mean": -792.6138292535463, "Train/ratio": {"_type": "histogram", "values": [46, 5, 12, 146, 24, 8, 7, 1, 3, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], "bins": [0.9007372856140137, 0.9172676205635071, 0.9337979555130005, 0.9503282308578491, 0.9668585658073425, 0.9833889007568359, 0.9999191761016846, 1.0164495706558228, 1.0329798460006714, 1.04951012134552, 1.0660405158996582, 1.0825707912445068, 1.0991010665893555, 1.1156314611434937, 1.1321617364883423, 1.1486921310424805, 1.165222406387329, 1.1817526817321777, 1.198283076286316, 1.2148133516311646, 1.2313437461853027, 1.2478740215301514, 1.264404296875, 1.2809346914291382, 1.2974649667739868, 1.3139952421188354, 1.3305256366729736, 1.3470559120178223, 1.363586187362671, 1.380116581916809, 1.3966468572616577, 1.413177251815796, 1.4297075271606445]}, "Loss/actor_loss": 0.9643546740137922, "Loss/critic_loss": 18.31453902593223, "Loss/entropy_loss": -1.8613729539096997, "entropy_coef": 0.7450000000000003, "_timestamp": 1700579330.3864207, "_runtime": 1685.3302488327026, "_step": 18, "_wandb": {"runtime": 1735}}