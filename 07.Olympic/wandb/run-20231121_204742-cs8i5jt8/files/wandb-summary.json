{"Num/train": 5, "Num/episodes": 62, "Num/timesteps": 24000, "Train/episode_reward_mean": -745.7657072467288, "Train/ratio": {"_type": "histogram", "values": [2, 0, 0, 2, 72, 15, 10, 14, 87, 23, 14, 2, 4, 4, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.44478362798690796, 0.48937270045280457, 0.5339617729187012, 0.5785508751869202, 0.6231399774551392, 0.6677290201187134, 0.7123181223869324, 0.7569072246551514, 0.8014962673187256, 0.8460853695869446, 0.8906744718551636, 0.9352635145187378, 0.9798526167869568, 1.0244417190551758, 1.06903076171875, 1.1136198043823242, 1.158208966255188, 1.2027980089187622, 1.2473870515823364, 1.2919762134552002, 1.3365652561187744, 1.3811542987823486, 1.4257434606552124, 1.4703325033187866, 1.5149215459823608, 1.5595107078552246, 1.6040997505187988, 1.648688793182373, 1.6932779550552368, 1.737866997718811, 1.7824560403823853, 1.827045202255249, 1.8716342449188232]}, "Loss/actor_loss": 1.7340330119515137, "Loss/critic_loss": 16.419710120488237, "Loss/entropy_loss": -2.391879350927568, "entropy_coef": 0.99, "_timestamp": 1700567891.1127596, "_runtime": 628.7902376651764, "_step": 4, "_wandb": {"runtime": 667}}